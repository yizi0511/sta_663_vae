{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "%run 'activation.ipynb' \n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "%run \"mnist.ipynb\"\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM:\n",
    "    \n",
    "    def __init__(self, n_v, n_h, W=None, b=None, c=None, k=1):\n",
    "        assert n_v != 0 and n_h != 0\n",
    "        self.n_v = n_v\n",
    "        self.n_h = n_h\n",
    "        shape = (n_h, n_v)\n",
    "        \n",
    "        self.W = W if W is not None else np.random.uniform(-1, 1, size=shape)\n",
    "        self.b = b if b is not None else np.zeros(n_v)\n",
    "        self.c = c if c is not None else np.zeros(n_h)\n",
    "\n",
    "        assert self.W.shape==shape and n_v == len(self.b) and n_h == len(self.c)\n",
    "        \n",
    "        self.k = k\n",
    "        self.training_done = True if W is not None and b is not None and c is not None else False\n",
    "        return\n",
    "        \n",
    "    def forward(self, V):\n",
    "        n_sample, n_v = V.shape\n",
    "        \n",
    "        hsignal = np.dot(V, self.W.T) + self.c\n",
    "        assert hsignal.shape == (n_sample, self.n_h)\n",
    "        Hp = sigmoid(hsignal)\n",
    "        \n",
    "        #s = np.random.uniform(0, 1, size=hsignal.shape)\n",
    "        #Hs = (s < Hp) * 1  # same as:\n",
    "        Hs = np.random.binomial(1, Hp, size=Hp.shape)\n",
    "        return Hp, Hs\n",
    "    \n",
    "    def backward(self, H):\n",
    "        n_sample, n_h = H.shape\n",
    "        \n",
    "        vsignal = np.dot(H, self.W) + self.b\n",
    "        assert vsignal.shape == (n_sample, self.n_v)\n",
    "        #print(vsignal)\n",
    "        Vp = sigmoid(vsignal)\n",
    "        \n",
    "        s = np.random.uniform(0, 1, size=vsignal.shape)\n",
    "        Vs = (s < Vp) * 1\n",
    "        return Vp, Vs\n",
    "\n",
    "    def gibbs(self, V):  #return (probability, samples) of visible units\n",
    "        Vs = V\n",
    "        for i in range(self.k):\n",
    "            Hp, Hs = self.forward(Vs)\n",
    "            Vp, Vs = self.backward(Hs)\n",
    "            \n",
    "        return Hp, Hs, Vp, Vs\n",
    "    \n",
    "    def contrastive_divergence(self, V, learning=0.01):\n",
    "        #set_trace()\n",
    "        n_sample, n_v = V.shape\n",
    "        \n",
    "        Vs = V\n",
    "        Hp, Hs, Vp_, Vs_ = self.gibbs(Vs)   # underscore _ refers to tilde for negative sample\n",
    "        Hp_, Hs_ = self.forward(Vs_)\n",
    "\n",
    "        Vs1 = np.mean(Vs, axis=0) \n",
    "        Vs2 = np.mean(Vs_, axis=0) \n",
    "        Hp1 = np.mean(Hp, axis=0)\n",
    "        Hp2 = np.mean(Hp_, axis=0)\n",
    "        Hs1 = np.mean(Hs, axis=0)\n",
    "        Hs2 = np.mean(Hs_, axis=0)\n",
    "        \n",
    "        # note, there are variances in how to compute the gradients.\n",
    "        # Hugo suggests:     h(v1)*v1 - h(v2)*v2\n",
    "        # Bengio suggests:   h1*v1 - h(v2)*v2\n",
    "        # My derivation:     h1(v1)*v1 - h2*v2 \n",
    "        \n",
    "        Eh_b = Vs1; Evh_b = Vs2      # Evh_b refers to the Expectation (over v and h) of -logP(v) gradient wrt b\n",
    "        \n",
    "        #Eh_c = Hs1; Evh_c = Hp2  # bengio\n",
    "        Eh_c = Hp1; Evh_c = Hp2  # hugo\n",
    "        #Eh_c = Hp1; Evh_c = Hs2  # Mine\n",
    "\n",
    "        g_b = Evh_b - Eh_b  # gradient of -logP(v) wrt b\n",
    "        g_c = Evh_c - Eh_c\n",
    "\n",
    "        Eh_W = np.outer(Eh_c, Eh_b) \n",
    "        Evh_W = np.outer(Evh_c, Evh_b)\n",
    "        g_W = Evh_W - Eh_W\n",
    "    \n",
    "        self.W -= g_W * learning\n",
    "        self.b -= g_b * learning\n",
    "        self.c -= g_c * learning        \n",
    "        return\n",
    "    \n",
    "    def reconstruct(self, V):\n",
    "        Hp, Hs = self.forward(V)\n",
    "        Vp, Vs = self.backward(Hp)\n",
    "        return Vp, Vs\n",
    "\n",
    "    # this is the API for app to use\n",
    "    def train(self, X, n_epoch=1, batch_size=10, learning=0.01, save_file=None):\n",
    "        if self.training_done: return\n",
    "        \n",
    "        save_file += \".rbm\"\n",
    "        self.train_model(X, n_epoch, batch_size, learning, save_file)\n",
    "        \n",
    "        self.training_done = True\n",
    "        return\n",
    "    \n",
    "    # this is the API for more complex network to use\n",
    "    def train_model(self, X, n_epoch=1, batch_size=10, learning=0.01, save_file=None):\n",
    "        \n",
    "        batch_size = batch_size if batch_size > 0 else 10\n",
    "        n_epoch = n_epoch if n_epoch > 0 else 1\n",
    "        n_sample = X.shape[0]\n",
    "        n_batch = n_sample//batch_size\n",
    "        for i in range(n_epoch):\n",
    "            for j in range(n_batch):\n",
    "                s = j*batch_size\n",
    "                V = X[s:s+batch_size]\n",
    "                self.contrastive_divergence(V, learning)\n",
    "\n",
    "        self.save_model(save_file + \".epochs\" + str(n_epoch))\n",
    "        return\n",
    "\n",
    "\n",
    "    def save_model(self, save_file):\n",
    "        dict = {'n_v':self.n_v, 'n_h':self.n_h, 'W':self.W, 'b':self.b, 'c':self.c}\n",
    "\n",
    "        save_file += \".\"+ str(self.n_v) + \"x\" + str(self.n_h)\n",
    "        with open(save_file, 'wb') as f:\n",
    "            pickle.dump(dict, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        return\n",
    "\n",
    "    @classmethod\n",
    "    def load_model(clazz, model_file):\n",
    "        with open(model_file, 'rb') as f:\n",
    "            m = pickle.load(f)\n",
    "\n",
    "        rbm = RBM(m['n_v'], m['n_h'], m['W'], m['b'], m['c'])\n",
    "        return rbm\n",
    "    \n",
    "    def show_features(self, shape, suptitle, count=-1):\n",
    "        maxw = np.amax(self.W)\n",
    "        minw = np.amin(self.W)\n",
    "        count = self.n_h if count == -1 or count > self.n_h else count\n",
    "        ncols = count if count < 14 else 14 \n",
    "        nrows = count//ncols\n",
    "        nrows = nrows if nrows > 2 else 3\n",
    "        fig = plt.figure(figsize=(ncols, nrows), dpi=100)\n",
    "        grid = Grid(fig, rect=111, nrows_ncols=(nrows, ncols), axes_pad=0.01)\n",
    "\n",
    "        for i, ax in enumerate(grid):\n",
    "            x = self.W[i] if i<self.n_h else np.zeros(shape)\n",
    "            x = (x.reshape(1, -1) - minw)/maxw\n",
    "            ax.imshow(x.reshape(*shape), cmap=mpl.cm.Greys)\n",
    "            ax.set_axis_off()\n",
    "\n",
    "        #fig.suptitle(suptitle, size=20)\n",
    "        fig.text(0.5,1, suptitle, fontsize=20, horizontalalignment='center')\n",
    "        fig.tight_layout()\n",
    "        #fig.subplots_adjust(top=0.85 + nrows*0.002)    #adjust suptitle position\n",
    "        plt.show()\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "run_control": {
     "marked": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# testing of the RBM code above\n",
    "\n",
    "class MNIST_RBM:\n",
    "\n",
    "    def __init__(self, n_v, n_h, load_file=None, save_file=\"mnist\", data_path=\"..\"):\n",
    "        if load_file is None: \n",
    "            self.rbm = RBM(n_v, n_h)\n",
    "        else:\n",
    "            self.rbm = RBM.load_model(load_file)\n",
    "        \n",
    "        self.train_input = MnistInput(\"train\", data_path)\n",
    "        self.test_input = MnistInput(\"test\", data_path)\n",
    "\n",
    "\n",
    "    def train(self, train_size=-1, n_epoch=100, batch_size=10, learning=0.01):\n",
    "        if self.rbm.training_done: return\n",
    "        \n",
    "        X = []\n",
    "        n_x = 0\n",
    "        for x, y in self.train_input.read(train_size):\n",
    "            X.append(x)\n",
    "            n_x += 1\n",
    "\n",
    "        X = np.array(X).reshape(n_x, -1) > 30\n",
    "        X = X*1 / 255\n",
    "        \n",
    "        self.rbm.train(X, n_epoch, batch_size, learning, save_file=\"mnist\")\n",
    "        return\n",
    "\n",
    "    def test_reconstruct(self, n):\n",
    "        X=[]; i=2*n\n",
    "        for x, y in self.test_input.read(n):\n",
    "            x *= np.random.binomial(1, i/(n*2), size=(28,28))\n",
    "            x = x * 2*n/i\n",
    "            x /= 255\n",
    "            X.append(x)\n",
    "            i -=1\n",
    "        \n",
    "        recon_X = []\n",
    "        for i in range(n):\n",
    "            Vp, Vs = self.rbm.reconstruct(X[i].reshape(1, -1))\n",
    "            recon_X.append(Vp)\n",
    "\n",
    "        return np.array(X).reshape(-1, 784), np.array(recon_X).reshape(-1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_rbm = None\n",
    "if __name__ == \"__main__\" and '__file__' not in globals():\n",
    "    \n",
    "    np.seterr(all='raise')\n",
    "    plt.close('all')\n",
    "    model_file = \"trained_models/mnist_rbm.784x500.epochs100\"\n",
    "    mnist_rbm = MNIST_RBM(28*28, 500, model_file)\n",
    "    #mnist_rbm = MNIST_RBM(28*28, 500, load_file=None)\n",
    "    mnist_rbm.train(10000, n_epoch=20, batch_size=100)\n",
    "    mnist_rbm.rbm.show_features((28,28), \"RBM learned features from MNIST \", 56)\n",
    "    x_sample, recon_x = mnist_rbm.test_reconstruct(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
