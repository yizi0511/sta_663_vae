{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the following exercise, submit your answer or provide an external link below. Please include the code, the output, and the explanation.\n",
    "\n",
    "Two models were trained using the following data:<br> \n",
    "x = [0, 1, 2, 3, 4] <br> \n",
    "y = [0.1, 0.9, 2.1, 2.9, 4.1] <br> \n",
    "Model 1 predicted y_1 = [0, 1, 2, 3, 4], and model 2 predicted y_2 = [0.1, 0.9, 2.1, 2.9, 4.1]. \n",
    "\n",
    "Write a Python function that computes the root mean square error (RMSE) for each model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([0.1, 0.9, 2.1, 2.9, 4.1])\n",
    "y_1 = np.array([0, 1, 2, 3, 4])\n",
    "y_2 = np.array([0.1, 0.9, 2.1, 2.9, 4.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Returns the root mean squared error (RMSE).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true: array-like of shape (n_samples,)\n",
    "        Ground truth target values.\n",
    "    \n",
    "    y_pred: array-like of shape (n_samples,)\n",
    "        Estimated target values.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    rmse: float \n",
    "        A non-negative floating point value (the best value is 0.0). \n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    \n",
    "    # Compute RMSE\n",
    "    rmse = np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "    \n",
    "    return rmse    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for model 1 is 0.100\n",
      "RMSE for model 2 is 0.000\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE for model 1 is {:.3f}\".format(root_mean_squared_error(y, y_1)))\n",
    "print(\"RMSE for model 2 is {:.3f}\".format(root_mean_squared_error(y, y_2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the test point (x, y) = (5, 5.1), model 1 predicted y_1 = 5, and model 2 predicted y_2 = 5.2. Which model is better and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "Model 2 is better. <br> \n",
    "Although both models have the same test RMSE (0.1) for the test point (5, 5.1). Model 2 is better because it has a smaller in-sample RMSE. A smaller in-sample RMSE suggests that model 2 is a better fit to the observed data. In comparison, model 1 performs less desirably on fitting the observed data as shown by y_1. It seems that model 1 is only capable of predicting an integer approximation to the true y. Since both the in-sample and out-of-sample RMSEs are low for model 2, model 2 is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
